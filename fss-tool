#!/usr/bin/env python3
"""
Import script for STWST-FSS / Foto Sammel Server
==================================================
author:(c) Michael Aschauer <m AT ash.to>
licenced under: GPL v3
see: http://www.gnu.org/licenses/gpl.html

"""

import sys
import os
import getopt
import datetime
from shutil import copyfile
from slugify import slugify
import pyexiv2
from subprocess import call
from termcolor import colored


EXIF_BIN = "/usr/bin/exiftool"
UID = 33
GID = 33
EXTENSIONS = [".jpg", ".jpeg", ".png", ".tif", ".tiff", ".gif",]


dokuwiki = "/var/www/html/fss.stwst.at"
media_dir = "data/media/"
pages_dir = "data/pages/"
archive_dir = "foto/archived"
publish_dir = "foto/published"
outdir = ""
indir = "./"
verbose = False

syncPages = False
syncTags = False
importFiles = False

dir_to_sync = False
counter = 0

def usage():
	"""Print Help usage"""
	print("""

usage: fss-tool [options] -i INPUT-DIR [-o OUTPUT-DIR]

OPTIONS:
========
	-h, --help              print usage
	-i, --input=DIR         input directory (interpreted depending on action)
	-o, --output=DIR        output directory (interpreted depending on action)
	-v, --verbose           verbose output

	actions:
	--import                import into FSS
	--sync-pages            sync dokuwiki's page structure to image files
	--sync-tags             NOT YET: sync exif/iptc/xmp tags

	fss directories overrides

	--dokuwiki-dir=DIR      DOKUWIKI Directory (default""" + dokuwiki + """)
	--archive-dir=DIR       Archive Directory (default: """ + archive_dir + """)
	--publish-dir=DIR       Archive Directory (default: """ + publish_dir + """)

""")


def process_args():
	"""Process command line arguments"""
	
	global indir, outdir, dokuwiki, arrchive_dir, publish_dir
	global importFiles, syncTags, syncPages
	global verbose

	try:
		opts, args = getopt.getopt(sys.argv[1:], "hi:o:v",
			["help", "input=","output=", "verbose",
				"import", "sync-pages", "sync-tags",
				"publish-dir=", "archive-dir=", "dokuwiki-dir=" ])
	except getopt.GetoptError as err:
		print(str(err)) # will print something like "option -a not recognized"
		usage()
		sys.exit(2)

	for o, a in opts:
		if o in ("-h", "--help"):
			usage()
			sys.exit()
		elif o in ("-o", "--outdir"):
			outdir = a
		elif o in ("-i", "--indir"):
			indir = a
		elif o in ("--dokuwiki-dir"):
			dokuwiki = a
		elif o in ("--archive-dir"):
			archive_dir = a
		elif o in ("--publish-dir"):
			publish_dir = a
		elif o in ("--sync-tags"):
			syncTags = True
		elif o in ("--sync-pages"):
			syncPages = True
		elif o in ("--import"):
			importFiles = True
		elif o in ("-v", "--verbose"):
			verbose = True
		else:
			usage();
			sys.exit()

	if len(sys.argv) <= 1:
		print("options required.")
		print("see help")
		sys.exit(2)
		

def import_files(indir, outdir):
	"""Imports files into dokuwikis media structure
	
	Keyword arguments:
    indir -- input directory
    outdir -- output directory (relative to dokuwikis media folder)
	"""

	global dokuwiki, arrchive_dir, publish_dir

	if indir[-1:] == "/":
		top = "./"
		os.chdir(indir)
	else:
		os.chdir(os.path.join(indir,".."))
		top = os.path.basename(indir)

	target_dir = os.path.join(dokuwiki, media_dir, archive_dir, outdir)
	
	print("IMPORTING FILES TO: " + target_dir + " ..")
	
	target_list = []
	
	for root, subdirs, files in os.walk(top):
		for f in files:
			filename, ext = os.path.splitext(f)
			ext = ext.lower()
			filename = slugify(filename.lower())
			
			dirs = root.split("/")
			folder = ''
			for i in range(0, len(dirs)):
				dirs[i] = slugify(dirs[i].lower())
				folder = os.path.join(folder, dirs[i])
		
			original = os.path.join(root, f)
			target = os.path.join(folder, filename)
			statinfo = os.stat(original)

			if not ext in EXTENSIONS:
				if (verbose):
					print(colored("ignore {}".format(original.encode("utf-8", "surrogateescape")), "yellow", attrs=["bold"]))
			elif statinfo.st_size == 0:
				print(colored("ERR: file is zero size - don't copy: {}".format(original), "red", attrs=["bold"]))
			else:
				i = 1
				while target in target_list:
					i += 1
					target = target + "-" + str(i)

				target_file = os.path.join(target_dir, target) + ext
				if (verbose):
					print("import {} -> {}".format(original, target_file))
				
				os.makedirs(os.path.split(target_file)[0], exist_ok=True)
				os.chown(os.path.split(target_file)[0], UID, GID)
				copyfile(original, target_file)
				os.chown(target_file, UID, GID)

				target_list.append(target)


def sync_pages(dir_to_sync):
	"""Creates dokuwiki page structure and galleries
	
	Keyword arguments:
    indir -- input directory (relative to dokuwikis media folder)
	"""	
	
	if not dir_to_sync:
		dir_to_sync = os.path.join(archive_dir, indir)
		
	print("SYNCING PAGES IN " + dir_to_sync +"..")
		
	source_dir = os.path.join(dokuwiki, media_dir, dir_to_sync)
	target_dir = os.path.join(dokuwiki, pages_dir, dir_to_sync)

	# create sidebar.txt file in top level
	outfile = os.path.join(target_dir, "sidebar") + ".txt"
	
	if (verbose):
		print("creating file: {}".format(outfile))
	
	os.makedirs(os.path.split(outfile)[0], exist_ok=True)
	f = open(outfile,"w")
	f.write("[[../|{{icon>level-up}}]][[../|..]]\n")

	for i in os.listdir(source_dir):
		if os.path.isdir(os.path.join(source_dir, i)) and i[0] != ".":
			f.write('[[/{}/|{{{{icon>folder}}}}]][[/{}/|{}]]  \n'.format(
				os.path.join(dir_to_sync,i), os.path.join(dir_to_sync,i), i))
	f.close()
	os.chown(outfile, UID, GID)
	os.chdir(source_dir)
	for root, subdirs, files in os.walk("."):

		for s in subdirs:
			if s[0] != ".":
				d = os.path.join(root, s)
				outfile = os.path.join(target_dir, d[2:],) + "/start.txt"
				sidebar = os.path.join(target_dir, d[2:],) + "/sidebar.txt"

				if (verbose):
					print("creating file: {}".format(sidebar))
				
				os.makedirs(os.path.split(sidebar)[0], exist_ok=True)
				f = open(sidebar,"w")
				f.write("[[../|{{icon>level-up}}]][[../|..]]\n")

				for i in os.listdir(d):
					if os.path.isdir(os.path.join(d,i)) and i[0] != ".":
						f.write(
							'[[/{}/|{{{{icon>folder}}}}]][[{}/|{}]]  \n'.format(
							os.path.join(dir_to_sync, d[2:],i),
							os.path.join(dir_to_sync, d[2:],i), i,
						))
				f.close()

				if (verbose):
					print("creating file: {}".format(outfile))
					
				f = open(outfile,"w")
				f.write("==== {} ====\n".format(s))
				f.write("{{gallery>?0&150x150&crop&norecursive}}\n")
				f.close()

				os.chown(outfile, UID, GID)	


def repair_tags(f):
	"""Repair tags of a file - calls exiftools

    Keyword arguments: 
    f -- input file
    """
	call(EXIF_BIN, "-all= -tagsfromfile @ -all:all -unsafe -icc_profile ".format(f))


def sync_tags(d):
	"""Sync tags
	
	reads in multiple tag values and collects them into the iptc variant.
	Logs erros if diverging tag contents are found.

    Keyword arguments: 
    d -- input directory
    """

	tags = {
		"title": [
			"Iptc.Application2.Headline", 
			],
		"description": [
			"Iptc.Application2.Caption",
			"Exif.Image.ImageDescription","Exif.Image.TIFFImageDescription", 
			],
		"author" : [
			"Iptc.Application2.Byline", "Iptc.Application2.Credit",
			"Exif.Image.Artis","Exif.Image.TIFFArtist",
			], 
		"copyright" : [
			"Iptc.Application2.Copyright",
			"Exif.Copyright","Exif.Image.TIFFCopyright",
			], 
		"keywords" :  [
			"Iptc.Application2.Keywords",
			"Exif.Image.Category"],
		"date": [
			"Iptc.Application2.DateCreated", 
			"Exif.Photo.DateTime", "Exif.Photo.DateTimeOriginal","Exif.Photo.DateTimeDigitized", "Exif.TIFFDateTime", 
			]
	}

	files_with_errors = []
	files_with_zerosize_error = []
	files_with_multitag_error = []
	
	print("SYNCING TAGS IN: " + d + " ..")	
	
	error_file_name = "synctags_errors.txt"
	error_file = open(error_file_name, "w")

	for root, subdirs, files in os.walk(d):		
		for f in files:
			filename, ext = os.path.splitext(f)
			ext = ext.lower()
			statinfo = os.stat(os.path.join(root,f))

			if statinfo.st_size == 0:
				error_file.write('{}\n'.format(os.path.join(root,f)))
				files_with_errors.append(os.path.join(root,f))
				files_with_zerosize_error.append(os.path.join(root,f))
				print("{}".format(os.path.join(root,f)))
				print(colored("  ERR: file is zero size", "red", attrs=["bold"]))
				print("\n")

			elif ext in EXTENSIONS:
				metadata = pyexiv2.ImageMetadata(os.path.join(root,f))
				metadata.read()
			
				# get available keys
				keys = metadata.iptc_keys
				for k in metadata.exif_keys:
					keys.append(k)
				
				# debug: print all keys
				#print("\n{}\n".format(keys))		
				
				# now process tags
				for tag in tags:
					
					tag_counter = 0
					tag_values = []
					tag_names = []
					tag_differ = False
					
					for t in tags[tag]:
						if t in keys:
							tag_counter += 1
							tag_names.append(t)
							
							if tag != "date":
								if type(metadata[t].raw_value) is str:
									tag_values.append(metadata[t].raw_value.strip())
								else:
									tag_values.append(metadata[t].raw_value[0].strip())
									
									if metadata[t].repeatable and len(metadata[t].raw_value) > 1:
										if (verbose):
											print("{}".format(os.path.join(root,f)))
											print(colored("  {} is repeatable and has {} values".format(t, len(metadata[t].raw_value)), "red", attrs=["bold"]))
											print("\n")
							else:
								if not type(metadata[t].value) is datetime.datetime:
									tag_values.append(metadata[t].value[0])
								else:
									tag_values.append(metadata[t].value)
									
								
					if len(tag_values) > 1:
						if (verbose):
							print("{}".format(os.path.join(root,f)))
							print(colored("  multiple tags for {}".format(tag.upper()), "magenta", attrs=["bold"]))
							print("  {}".format(tag_names))
							print("\n")
					
						# set all datetimes to dates
						if tag == "date":
							for i, v in enumerate(tag_values):
								if type(v) == datetime.datetime:
									tag_values[i] = v.date()	
									
						# has mismatching tag values
						if len(set(tag_values)) > 1:
							tag_differ = True
							error_file.write('{}\n'.format(os.path.join(root,f)))
							files_with_errors.append(os.path.join(root,f))
							files_with_multitag_error.append(os.path.join(root,f))
								
					# has mismatching tag values	
					if tag_differ:	
						print("{}".format(os.path.join(root,f)))
						print(colored("  tag mismatch for {}".format(tag.upper()), "red", attrs=["bold"]))
						print("  ----------------------")
						for i, t in enumerate(tag_names):
							print(colored("    {}:".format(t), "yellow", attrs=["bold"]))
							print("      {}:".format(tag_values[i]))
						print("  ----------------------")
						print(colored("   {} mismatching tags for {}".format(tag_counter, tag), "red", attrs=["bold"]))
						print("\n")

					else:
						if len(tag_values) > 0:
							# write IPTC tag if no set
							if not tags[tag][0] in keys:
								if (verbose):
									print("{}".format(os.path.join(root,f)))
									print(colored("  setting {} to {}".format(tags[tag][0], tag_names[0]), "cyan", attrs=["bold"]))
									print("\n")
								metadata[tags[tag][0]] = [tag_values[0]]
								metadata.write()
	
	error_file.close()
	
	if len(files_with_errors) > 0:	
		print("found {} file/s with size zero".format(len(files_with_zerosize_error)))
		print("found {} file/s with multiple values for matching tags".format(len(files_with_multitag_error)))
		print("See " + error_file_name + " for a list of these files")
	else:
		os.unlink(error_file_name)


if __name__ == '__main__':
	process_args()

	if importFiles:
		cwd = os.getcwd()
		
		import_files(indir, outdir)
		
		os.chdir(cwd)
		target_dir = os.path.join(archive_dir, outdir)
		(head,tail) = os.path.split(target_dir)
		sync_pages(head)
		
		os.chdir(cwd)
		target_dir = os.path.join(dokuwiki, media_dir, target_dir)
		sync_tags(target_dir)
		
	elif syncPages:
		sync_pages(dir_to_sync)
		
	elif syncTags:
		sync_tags(indir)
